---
title: "ICES VMS datacall: present -> dplyr (-> duckdb)"
code-fold: false
number-sections: true
number-depth: 3
---


> **Note:** _This document is actively evolving. Feedback, corrections, and contributions are welcome!_

# Preamble

This document illustrates as well as reviews the ICES VMS datacall workflow, highlighting both the legacy and alternative data processing approaches. 

The goal of this exercise was to clarify the process, if only personally for one that resides mostly in the tidyverse environment. Moving to the tidyverse, more specifically using the {dplyr}-verbs is not a goal in itself, but rather a stepping stone towards being able to use backend translation of that type of R code to SQL, via the {dbplyr}-package. Processing the data via in-memory **duckdb** reading from sweeps of files residing on the computer via R script, without importing the whole datasets into R is the ultimate aim.

## TODO

- Implement "split-among-pings" the new way
- Expand spatial procedures (points-in-polygons for ICES areas, harbours, habitats)
- DuckDB section: save processed files as Parquet and show how to start from there


## The Story So Far

The ICES VMS datacall codebase is a legacy, shaped by contributions from multiple developers, each with their preferred R dialect (`data.table`, `tidyverse`, etc.). While `{vmstools}` remains foundational, many new functions have accumulated over time—often as standalone scripts with limited documentation.

- **Challenge:** The codebase is heterogeneous and difficult to refactor wholesale. Incremental, undocumented changes can also introduce long-term maintenance risks.
- **Aim:** This document provides an external review and stepwise modernization, focusing on reproducibility, transparency, and scalability. Note that the author is not a long-time datacall maintainer, but rather a user and reviewer of the latest code version.

## Approach

- Use the `dplyr` grammar throughout, to facilitate translation across:
- in-memory data frames,
- traditional transactional databases,
- on-the-fly in-memory databases (e.g., DuckDB).
- **Rationale:**
- Out-of-memory workflows help avoid system crashes as data volumes grow (e.g., higher VMS ping frequency, new data sources like AIS/SSF).
- Anticipate future requirements and enable smooth scaling without major rewrites.

- **Coding principles:**
- Use and expose generic, well-tested `dplyr` functions.
- Use pipeline for readability
- Log all data quality checks as part of the pipeline, not in separate object.
- Minimize redundant date/time variables—generate datetime columns once upfront, and reconstruct character formats only if needed later.
- Split EFLALO data into "trips" and "events" and use those when assigning events to pings.

Downstream, compare the "official" 2025 script ("datacall") and a modernized approach ("myway") for validation.

## Packages and ad-hoc functions

We rely on several packages and external scripts/functions. The list below includes both CRAN and GitHub dependencies.

```{r packages}
library(data.table)  # Required for some datacall functions
library(vmstools)    # Provides foundational VMS/logbook utilities
library(tidyverse)   # Modern data manipulation and piping
library(duckdb)      # For scalable, out-of-memory data processing

### datacall functions - can not source global.R, here a datacall trip_assign as a temporary gist
source("https://gist.githubusercontent.com/einarhjorleifsson/deee46b493f1f95e95e905c15f1c2432/raw/e2d2a0a8241ac8f9c86c3971de677ff260d7319d/rb_trip_assign.R")

### ramb functions
source("https://raw.githubusercontent.com/einarhjorleifsson/ramb/refs/heads/main/R/rb_sum_across.R")
# source(here::here("R/dc_spread_cash_and_catch_v2.R"))

rb_getCodeList <- function(code_type, from_web = TRUE) {
  if(from_web) {
    icesVocab::getCodeList(code_type)
  } else {
    readr::read_rds(paste0(here::here("data/icesVocab"), "/", code_type, ".rds"))
  }
}
```

## Data

For illustration, we use the `{vmstools}` built-in datasets and ICES vocabularies.

```{r data}
data(eflalo)
eflalo_org <- eflalo  # Make a copy for donwstream comparisons
data(tacsat)

# Advice to change from_web = FALSE to from_web = TRUE, have temporary problems
iv_gear <-   rb_getCodeList("GearType", from_web = FALSE)$Key
iv_target <- rb_getCodeList("TargetAssemblage", from_web = FALSE)$Key
iv_met6 <-   rb_getCodeList("Metier6_FishingActivity", from_web = FALSE)$Key
```

## Date-time consolidation, sum catch and weight & unique rownumber

Convert and consolidate all relevant date and datetime fields up front.

- This reduces clutter and makes downstream processing simpler

- Unique row IDs are generated for easy traceability and comparison checks

```{r consolidate}
remove <- TRUE  # Decide if you want retain orginal variables if new are created
eflalo <- 
  eflalo |> 
  as_tibble() |>
  rename(LE_MET6 = LE_MET_level6) |> 
  unite(col = "D_DATIM", FT_DDAT, FT_DTIME, sep = " ", remove = remove) |> 
  unite(col = "L_DATIM", FT_LDAT, FT_LTIME, sep = " ", remove = remove) |> 
  # should really be FT_DDATIM and FT_LDATIM - that is what splitAmongPings checks for
  mutate(D_DATIM = dmy_hms(D_DATIM, tz = "UTC"),       # Note: {vmstools} used "GMT"
         L_DATIM = dmy_hms(L_DATIM, tz = "UTC"),
         LE_CDAT = dmy(LE_CDAT),
         .after = FT_REF) |> 
  arrange(VE_COU, VE_COU, LE_CDAT) |> 
  mutate(.eid = 1L:n()) |> 
  select(.eid, VE_COU, VE_REF, VE_LEN, VE_KW, VE_TON, everything()) |> 
  # for the demo, reduces the clutter
  rb_sum_across("LE_KG", remove = remove) |> 
  rb_sum_across("LE_EURO", remove = remove)
tacsat <- 
  tacsat |> 
  as_tibble() |> 
  # have to keep SI_DATE, because used in trip_assign
  unite("SI_DATIM", SI_DATE, SI_TIME, sep = " ", remove = FALSE) |>
  select(-SI_TIME) |> 
  # UTC does not recognize "29/02/1801", not a leap year
  mutate(SI_DATIM = dmy_hms(SI_DATIM, tz = "UTC"),
         SI_DATE = dmy(SI_DATE)) |> 
  # hence filter upfront
  filter(!is.na(SI_DATIM)) |> 
  arrange(VE_COU, VE_REF, SI_DATIM) |> 
  # possibly part of the checks, but it is natural to do it upfront
  distinct(VE_COU, VE_REF, SI_DATIM, .keep_all = TRUE) |> 
  arrange(VE_COU, VE_COU, SI_DATIM) |> 
  mutate(.pid = 1L:n(),
         .before = VE_COU)
```

# Pre-processing

## eflalo: Checks

All records are assessed for potential errors or issues, which are logged in a `checks` column. This makes it easy to review and filter problematic records.
Here bookkeeping of potential filtering of records is part of the pipe-flow process. Additional checks can easily be implemented and then in the end the user can decide what records should be filtered, based on values in "checks".

```{r eflalo-checks}
eflalo <- 
  eflalo |> 
  # only needed if one wants to do additional testing
  separate(LE_MET6, into = c(".m6gear", ".m6target", ".m6mesh", ".m6rest"), sep = "_", remove = FALSE, extra = "merge") |> 
  separate(.m6mesh, into = c(".m1", ".m2"), sep = "-", remove = FALSE, fill = "right", convert = TRUE) |> 
  separate(LE_ID, into = c(".etid", ".egear", ".eir"), sep = "-", remove = FALSE) |> 
  # TODO: Deal with .m1 or .m2 being characters
  #mutate(.m2 = case_when(is.na(.m2) & as.character(.m1) == "0" ~ "0",
  #                       .default = .m2)) |> 
  mutate(
    checks = case_when(                                                   # datacall
      # Catch record outlier - code pending                               # 1.3.2
      base::duplicated(paste(VE_REF, LE_ID, LE_CDAT)) ~ "01 duplicated events",   # 1.3.3
      is.na(D_DATIM) | is.na(L_DATIM) ~ "02 impossible time",                       # 1.3.4
      year(D_DATIM) == (year(L_DATIM) - 1) ~ "03 new years trip",                   # 1.3.5
      D_DATIM > L_DATIM ~ "04 departure before arrival",                           # 1.3.6
      # "05 overlapping trips  - code pending                             # 1.3.7
      !LE_GEAR %in% iv_gear ~ "06 gear (metier 4) invalid",                  # 1.4.1
      !LE_MET6 %in% iv_met6 ~ "07 metier 6 invalid",                         # 3.5.5
      # Addendum, needs discussions
      !between(LE_CDAT, as_date(D_DATIM), as_date(L_DATIM)) ~ "ok - 08 catch date not within trip",
      # metier level 6 component checks
      LE_GEAR != .m6gear ~ "ok - 01 met6 gear different from gear",
      !.m6target %in% iv_target ~ "ok - 10 met6 target invalid",
      # event id component checks
      FT_REF != .etid ~ "ok - 11 event id tripid different from tripid",
      LE_GEAR != .egear ~ "ok - 12 event id gear different from gear",
      LE_RECT != .eir ~ "ok - 13 event id rectangle different from rectangle",
      # Pending solution prior to case_when applied
      #!between(mesh, as.integer(.m1), .m2) ~ "11 mesh size not in the met6 range",
      .default = "ok")
  )
eflalo |> 
  count(checks) |> 
  mutate('%' = round(n / sum(n) * 100, 2)) |> 
  knitr::kable(caption = "Logbooks: All records not starting with 'ok' will be filtered downstream")

eflalo <-
  eflalo |> 
  select(-c(.etid, .egear, .eir,
            .m6gear, .m6target, .m6mesh, .m1, .m2, .m6rest)) |> 
  # You may want to use another filter
  filter(str_starts(checks, "ok")) |> 
  select(-checks)
```

## eflalo: Split eflalo into trip and event table

Splitting the data clarifies intent as well as making "myway" downstream code flow simpler.

```{r split-eflalo}
trips <-
  eflalo |> 
  group_by(VE_COU, VE_REF, FT_REF) |> 
  mutate(weight = sum(LE_KG),
         price = sum(LE_EURO)) |> 
  ungroup() |> 
  # here we could add variables corresponding to the highest trip
  select(VE_COU, VE_REF, VE_LEN, VE_KW, VE_TON, FT_REF, D_DATIM, L_DATIM, weight, price) |> 
  distinct(VE_COU, VE_REF, FT_REF, .keep_all = TRUE) |> 
  mutate(.tid = 1L:n(),
         .before = VE_COU)
events <- 
  eflalo |> 
  select(.eid, VE_COU, VE_REF, FT_REF, starts_with("LE_")) |> 
  # reduce the clutter for this demo test only - do not use generic code
  janitor::remove_empty(which = "cols")
```


```{r}
# TODO: printout with smaller fonts
trips
```

As for the event table we have:

```{r}
# TODO: printout with smaller fonts
events
```

## eflalo: Create higest_event and highest trip tables

I think the intent is of the datacall `trip_assing` function is: 

1. For each fishing day, add the values of gear, mesh and met6 from the highest event catch record within the day (no summation done a priori)
2. For non-fishing days, add the values of gear, mesh and met6 from the highest trip catches

One way to think about this in the `dplyr`-flow is to create two tables, highest event table and highest trip table. We will use these two tables in "myway" flow downstream, that code flow being being fully independent of the `assign_trip`-function.

```{r eflalo-highest}
highest_event <-
  events |> 
  arrange(desc(LE_KG)) |> 
  group_by(VE_COU, VE_REF, FT_REF, LE_CDAT) |> 
  slice(1) |> 
  ungroup() |> 
  select(VE_COU, VE_REF, FT_REF, LE_CDAT, LE_GEAR, LE_MSZ, LE_MET6, LE_RECT)
highest_event

highest_trip <-
  events |> 
  group_by(VE_COU, VE_REF, FT_REF, LE_GEAR, LE_MSZ, LE_MET6, LE_RECT) |> 
  summarise(LE_KG = sum(LE_KG),
            .groups = "drop") |> 
  arrange(desc(LE_KG)) |> 
  group_by(VE_COU, VE_REF, FT_REF) |> 
  slice(1) |> 
  ungroup() |> 
  select(VE_COU, VE_REF, FT_REF, .LE_GEAR = LE_GEAR, .LE_MSZ = LE_MSZ, 
         .LE_MET6 = LE_MET6, .LE_RECT = LE_RECT)
highest_trip
```

Add test here to illustrate the intent

## tacsat: Checks

```{r tacsat-checks}
it_min <- 5 * 60 # Interval threshold minimum [units: seconds]
tacsat <- 
  tacsat |> 
  group_by(VE_COU, VE_REF) |> 
  mutate(dt = c(it_min, diff(unclass(SI_DATIM)))) |>
  ungroup() |> 
  mutate(
    checks = 
      case_when(
        is.na(VE_COU) ~ "00 1 no country id",
        is.na(VE_REF) ~ "00 2 no vessel id",
        is.na(SI_DATIM) ~ "00 3 no time",
        is.na(SI_LONG) ~  "00 4 no lon",
        is.na(SI_LATI) ~  "00 5 no lat",
        is.na(SI_SP) ~ "00 6 no speed",
        base::duplicated(paste(VE_COU, VE_REF, SI_LONG, SI_LATI, SI_DATIM)) ~ "02 duplicates",
        !between(SI_LONG, -180, 180) | !between(SI_LATI, -90, 90) ~ "03 coordinates out of bound",
        dt < it_min ~ "04 time interval exceeds threshold",
        .default = "ok")
  )

tacsat |>
  count(checks) |>
  mutate('%' = round(n / sum(n) * 100, 2)) |>
  knitr::kable(caption = "VMS: All records not 'ok' will be filtered downstream")
tacsat <- 
  tacsat |> 
  filter(str_starts(checks, "ok")) |>
  select(-c(checks))
trails <- tacsat  # for myway
```


# Analysis 

## Add trip information to pings

::: {.panel-tabset}

### datacall

* First we add trip using the legacy `vmstools::mergeEflalo2Tacsat`
* Then use a loop to add fixed trip related variables, (We do not expect vessel length, power or tonnage to change within a trip)

```{r add-trip_datacall}
tacsat <-   # normally called tacsatp in the code flow 
  mergeEflalo2Tacsat(eflalo |> as.data.frame(),
                     tacsat |> as.data.frame())
# NOTE: event information added downstream - to clarify thinking
cols <- c("VE_LEN", "VE_KW")
for (col in cols) {
  tacsat[[col]] <- eflalo[[col]][match(tacsat$FT_REF, eflalo$FT_REF)]
}
```

### myway

```{r add-trip_myway}
trails <- 
  trails |> 
  left_join(trips,
            by = join_by(VE_COU, VE_REF, between(SI_DATIM, D_DATIM, L_DATIM)),
            relationship = "many-to-one") |> 
  # No longer needed
  select(-c(D_DATIM, L_DATIM))
```

### comparison

```{r add-trip-comparison}
comparison <- 
  tacsat |> 
  as_tibble() |> 
  select(.pid, VE_COU, VE_REF, FT_REF, length_dc = VE_LEN, kw_dc = VE_KW) |> 
  left_join(trails |> select(.pid, VE_COU, VE_REF, FT_REF, length_mw = VE_LEN, kw_mw = VE_KW),
            by = join_by(.pid, VE_COU, VE_REF, FT_REF)) |> 
  filter(length_dc != length_mw | kw_dc != kw_mw) |> 
  select(-c(.pid, FT_REF)) |> 
  distinct()
tacsat |> 
  as_tibble() |> 
  select(.pid, VE_COU, VE_REF, FT_REF, length_dc = VE_LEN, kw_dc = VE_KW) |> 
  left_join(trails |> select(.pid, VE_COU, VE_REF, FT_REF, length_mw = VE_LEN, kw_mw = VE_KW)) |> 
  filter(length_dc != length_mw | kw_dc != kw_mw) |> 
  select(-c(.pid, FT_REF)) |> 
  distinct() |> 
  left_join(eflalo_org |> 
              filter(VE_REF %in% unique(comparison$VE_REF)) |> 
              select(VE_REF, VE_LEN, VE_KW) |> 
              distinct()) |> 
  knitr::kable(caption = "Assigning vessel info to pings - discrepancies\n'_dc': datacall, '_mw: myway, original from eflalo\nSeems like myway same as the original")
```

Seems "myway" is correct given the original, so something to check in the datacall flow

:::

## Add event information to pings

This step is is not a precursor to the next step - consider rearranging ...

::: {.panel-tabset}

### datacall

```{r add-event-datacall}
## Add gear, mesh and met6 to pings --------------------------------------------
### datacall ----------------------------------------------------------------
# Now add the event info - this step needed so that next step works - could be simplified
cols <- c("LE_GEAR", "LE_MSZ", "LE_RECT", "LE_MET6")
for (col in cols) {
  tacsat[[col]] <- eflalo[[col]][match(tacsat$FT_REF, eflalo$FT_REF)]
}

tacsat_LE_GEAR <- trip_assign(tacsat, eflalo, col = "LE_GEAR",  haul_logbook = F)
# Here and subsequently, replaced %!in% with %in%, moving the ! upfront
tacsat <- rbindlist(list(tacsat[!tacsat$FT_REF %in% tacsat_LE_GEAR$FT_REF,], tacsat_LE_GEAR), fill = T, ignore.attr=TRUE)

tacsat_LE_MSZ <- trip_assign(tacsat, eflalo, col = "LE_MSZ",  haul_logbook = F)
tacsat <- rbindlist(list(tacsat[!tacsat$FT_REF %in% tacsat_LE_MSZ$FT_REF,], tacsat_LE_MSZ), fill = T)

tacsat_LE_RECT <- trip_assign(tacsat, eflalo, col = "LE_RECT",  haul_logbook = F)
tacsat <- rbindlist(list(tacsat[!tacsat$FT_REF %in% tacsat_LE_RECT$FT_REF,], tacsat_LE_RECT), fill = T)

tacsat_LE_MET <- trip_assign(tacsat, eflalo, col = "LE_MET6",  haul_logbook = F)
tacsat <- rbindlist(list(tacsat[!tacsat$FT_REF %in% tacsat_LE_MET$FT_REF,], tacsat_LE_MET), fill = T)
```

### myway

Here we use a left join to the trails and the final values consolidated. Take note that the joining is as follows:

```
1. highest_event (    fishing day): join_by(VE_COU, VE_REF, FT_REF, SI_DATE == LE_CDAT)
2. highest_trips (non-fishing day): join_by(VE_COU, VE_REF, FT_REF)
```

```{r add-event-myway}
trails <- 
  trails |> 
  left_join(highest_event,
            by = join_by(VE_COU, VE_REF, FT_REF, SI_DATE == LE_CDAT),
            relationship = "many-to-one") |> 
  left_join(highest_trip,
            by = join_by(VE_COU, VE_REF, FT_REF),
            relationship = "many-to-one") |> 
  mutate(LE_GEAR = case_when(is.na(LE_GEAR) & !is.na(.LE_GEAR) ~ .LE_GEAR,
                             .default = LE_GEAR),
         LE_MSZ = case_when(is.na(LE_MSZ) & !is.na(.LE_MSZ) ~ .LE_MSZ,
                            .default = LE_MSZ),
         LE_MET6 = case_when(is.na(LE_MET6) & !is.na(.LE_MET6) ~ .LE_MET6,
                             .default = LE_MET6),
         LE_RECT = case_when(is.na(LE_RECT) & !is.na(.LE_RECT) ~ .LE_RECT,
                             .default = LE_RECT)) |> 
  select(-c(.LE_GEAR, .LE_MSZ, .LE_MET6, .LE_RECT))
```

### comparison

```{r add-event-comparison}
comparison <- 
  tacsat |> 
  as_tibble() |> 
  select(.pid, VE_COU, VE_REF, FT_REF, LE_GEAR, LE_MSZ, LE_MET6, LE_RECT) |> 
  left_join(trails |> select(.pid, VE_COU, VE_REF, FT_REF, 
                             .LE_GEAR = LE_GEAR, .LE_MSZ = LE_MSZ, 
                             .LE_MET6 = LE_MET6, .LE_RECT = LE_RECT),
            by = join_by(.pid, VE_COU, VE_REF, FT_REF)) |> 
  # reorder
  select(.pid, VE_COU, VE_REF, FT_REF, LE_GEAR, .LE_GEAR, LE_MSZ, .LE_MSZ, LE_MET6, .LE_MET6, LE_RECT, .LE_RECT)
comparison |> 
  #filter(LE_GEAR != .LE_GEAR  | LE_MSZ != .LE_MSZ | LE_MET6 != .LE_MET6) |> 
  mutate(gear = if_else(LE_GEAR == .LE_GEAR, "yes", "no", "yes_na"),
         mesh = if_else(LE_MSZ  == .LE_MSZ, "yes", "no", "yes_na"),
         met6 = if_else(LE_MET6 == .LE_MET6, "yes", "no", "yes_na"),
         rect = if_else(LE_RECT   == .LE_RECT, "yes", "no", "yes_na")) |> 
  count(gear, mesh, met6, rect) |> 
  mutate('%' = round(n / sum(n) * 100, 2)) |> 
  knitr::kable(caption = "Assigning events info to pings - discrepancies between datacall vs. myway\nNeeds a revisit, at least the rectangles")
# For now let's look at the event records were gear and rectangles are not the same (33 records)
problem_trips <- 
  comparison |> 
  #filter(LE_GEAR != .LE_GEAR  | LE_MSZ != .LE_MSZ | LE_MET6 != .LE_MET6) |> 
  filter(LE_GEAR != .LE_GEAR  & LE_RECT != .LE_RECT) |> 
  select(VE_COU, VE_REF, FT_REF) |> 
  distinct()
problem_events <- 
  problem_trips |> 
  left_join(events |> select(VE_REF, FT_REF, LE_CDAT, LE_GEAR, LE_RECT, LE_KG)) |> 
  arrange(LE_CDAT, desc(LE_KG))
problem_events |> knitr::kable(caption = "Events table, original data")
problem_events |> 
  inner_join(trails) |> 
  arrange(SI_DATIM) |> 
  select(.pid, SI_DATIM, VE_REF, FT_REF, LE_CDAT, SI_DATE, LE_GEAR, LE_RECT, LE_KG) |> 
  #distinct(VE_REF, FT_REF, LE_CDAT, SI_DATE, LE_GEAR, LE_RECT, LE_KG, .keep_all = TRUE) |> 
  knitr::kable(caption = "Discrepancies - myway")
problem_events |> 
  inner_join(tacsat) |> 
  arrange(SI_DATIM) |> 
  select(.pid, SI_DATIM, VE_REF, FT_REF, LE_CDAT, SI_DATE, LE_GEAR, LE_RECT, LE_KG) |> 
  #distinct(VE_REF, FT_REF, LE_CDAT, SI_DATE, LE_GEAR, LE_RECT, LE_KG, .keep_all = TRUE) |> 
  knitr::kable(caption = "Discrepancies - datacall")
# TODO: Check why something is wrotten in the State of Denmark
print("There is a pending issue, the two 'ways' do not give the same results")
```
:::

## Interval and state

Here I will keep things simple, applying a simple speed filter for both the datacall and myway, also throwing in interval along the way:

```{r}
speed_criteria <- 
  tribble(~LE_GEAR, ~s1,  ~s2,
          "GN",       1,    6,
          "GNS",      1,    6,
          "OTB",      1,    6,
          "OTM",      1,    6,
          "PTB",      1,    6,
          "TBB",      1,    6)

tacsat <- 
  tacsat |>
  arrange(VE_COU, VE_REF, SI_DATIM) |> 
  group_by(VE_COU, VE_REF, FT_REF) |> 
  mutate(INTV = c(NA_real_, diff(unclass(SI_DATIM))) / 60) |> # in minutes
  fill(INTV, .direction = "up") |> 
  ungroup() |> 
  left_join(speed_criteria) |> 
  mutate(SI_STATE = case_when(is.na(SI_SP) ~ NA,
                              between(SI_SP, s1, s2) ~ 1,
                              !between(SI_SP, s1, s2) ~ 0,
                              .default = -9999)) |> 
  select(-c(s1, s2))

trails <- 
  trails |>
  arrange(VE_COU, VE_REF, SI_DATIM) |> 
  group_by(VE_COU, VE_REF, FT_REF) |> 
  mutate(INTV = c(NA_real_, diff(unclass(SI_DATIM))) / 60) |> # in minutes
  fill(INTV, .direction = "up") |> 
  ungroup() |> 
  left_join(speed_criteria) |> 
  mutate(SI_STATE = case_when(is.na(SI_SP) ~ NA,
                              between(SI_SP, s1, s2) ~ 1,
                              !between(SI_SP, s1, s2) ~ 0,
                              .default = -9999)) |> 
  select(-c(s1, s2))
```

interval checks (do a proper one, should also check for negative intverals)

```{r}
table(tacsat$INTV == 0, useNA = "ifany")
table(trails$INTV == 0, useNA = "ifany")
```


Speed checks:
```{r}
tacsat |> 
  mutate(in_eflalo = ifelse(FT_REF %in% unique(eflalo$FT_REF), "yes", "no")) |>  
  count(in_eflalo, SI_STATE)
trails |> 
  mutate(in_eflalo = ifelse(FT_REF %in% unique(eflalo$FT_REF), "yes", "no")) |>  
  count(in_eflalo, SI_STATE)
trails |> 
  mutate(in_eflalo = ifelse(FT_REF %in% unique(eflalo$FT_REF), "yes", "no")) |> 
  filter(SI_STATE >= 0) |> 
  count(in_eflalo, SI_STATE, LE_GEAR)
```

For now remove the records where there is not LE_GEAR assigned to trips and SI_STATE is -9999
```{r}
tacsat <- tacsat |> filter(!is.na(LE_GEAR), INTV > 0)
trails <- trails |> filter(!is.na(LE_GEAR), INTV > 0)
```


## Split among pings

::: {.panel-tabset}

### datacall

```{r}
eflalo2 <- 
  eflalo |> 
  #filter(FT_REF == TRIP) |> 
  # vmstools::splitAmongPings checks if trips cross newyear and stops if any
  #  hence need these (Note: not in d/m/y format, may cause trouble)
  mutate(FT_DDAT = as.character(as_date(D_DATIM)),
         FT_DTIME = str_sub(as.character(D_DATIM), 12),
         FT_LDAT = as.character(as_date(L_DATIM)),
         FT_LTIME = str_sub(as.character(L_DATIM), 12))

tacsat2 <-
  tacsat |> 
  #filter(FT_REF == TRIP) |> 
  select(-LE_RECT)

tacsatEflalo <-  splitAmongPings(
  # create an issue in [vmstools}
  tacsat = tacsat2 |> as.data.frame(),
  eflalo = eflalo2 |> as.data.frame(),
  variable = "all",
  level = c("trip", "ICESrectangle", "day"),
  conserve = FALSE 
  #, by = "INTV"
) |> 
  as_tibble()
```

### myway

```{r}
# Fix variable names upstream, idea is to make a distinction between
#  Standard TACSAT and EFLALO variable names and types and 
#  derived or external variables
trails2 <- 
  trails |> 
  select(-LE_RECT) |> 
  rename(time = SI_DATIM,
         state = SI_STATE) |> 
  mutate(ir = ramb::rb_d2ir(SI_LONG, SI_LATI),
         state = as.integer(state))
events2 <- 
  events |> 
  rename(e_date = LE_CDAT) |> 
  group_by(VE_COU, VE_REF, FT_REF, LE_RECT, e_date) |> 
  summarise(LE_KG = sum(LE_KG, na.rm = TRUE),
            LE_EURO = sum(LE_EURO, na.rm = TRUE),
            .groups = "drop") |> 
  mutate(.eid = as.integer(1:n()),
         .before = VE_COU)
trails_spread2 <- 
  ramb::dc_spread_cash_and_catch(
    trails = trails2,
    events = events2,
    remove_diagnostic = FALSE
  )
```

### comparison

```{r}
comp <-
  tacsatEflalo |> 
  select(FT_REF, .pid, dc = LE_KG) |> 
  full_join(trails_spread2 |> 
              select(.pid, rb = LE_KG, .how, ir))
comp |> 
  group_by(FT_REF) |> 
  summarise(dc = sum(dc, na.rm = TRUE),
            rb = sum(rb, na.rm = TRUE)) |> 
  filter(!near(dc, rb)) |> 
  knitr::kable(caption = "List of FT_REFs that are not the same")
comp |> 
  ggplot(aes(dc / 1e3, rb / 1e3)) +
  theme_bw() +
  geom_abline(linewidth = 2, colour = "pink") +
  geom_point(size = 0.5) +
  scale_x_log10() +
  scale_y_log10() +
  labs(title = "Comparison of catch spread",
       x = "datacall", y = "myway",
       caption = "Guess there is more than one way to skin a cat")
```

:::



```{r duckdb}
#| eval: false
#| echo: false
duck_highest_event_catch_per_day <-
  duck_events |> 
  arrange(desc(LE_KG)) |> 
  group_by(VE_COU, VE_REF, FT_REF, LE_CDAT) |> 
  filter(row_number()==1) |> # instead of slice
  ungroup() |> 
  select(VE_COU, VE_REF, FT_REF, LE_CDAT, LE_GEAR, LE_MSZ, LE_MET6, LE_RECT)
duck_highest_trip_catches <-
  duck_events |> 
  group_by(VE_COU, VE_REF, FT_REF, LE_GEAR, LE_MSZ, LE_MET6, LE_RECT) |> 
  summarise(LE_KG = sum(LE_KG),
            .groups = "drop") |> 
  arrange(desc(LE_KG)) |> 
  group_by(VE_COU, VE_REF, FT_REF) |> 
  filter(row_number()==1) |> # instead of slice
  ungroup() |> 
  select(VE_COU, VE_REF, FT_REF, .LE_GEAR = LE_GEAR, .LE_MSZ = LE_MSZ, 
         .LE_MET6 = LE_MET6, .LE_RECT = LE_RECT)
duck_trails <- 
  duck_trails |> 
  left_join(duck_highest_event_catch_per_day,
            by = join_by(VE_COU, VE_REF, FT_REF, SI_DATE == LE_CDAT)) |> 
  # relationship = "many-to-one") |> 
  left_join(duck_highest_trip_catches,
            by = join_by(VE_COU, VE_REF, FT_REF)) |> 
  # relationship = "many-to-one") |> 
  mutate(LE_GEAR = case_when(is.na(LE_GEAR) & !is.na(.LE_GEAR) ~ .LE_GEAR,
                             .default = LE_GEAR),
         LE_MSZ = case_when(is.na(LE_MSZ) & !is.na(.LE_MSZ) ~ .LE_MSZ,
                            .default = LE_MSZ),
         LE_MET6 = case_when(is.na(LE_MET6) & !is.na(.LE_MET6) ~ .LE_MET6,
                             .default = LE_MET6),
         LE_RECT = case_when(is.na(LE_RECT) & !is.na(.LE_RECT) ~ .LE_RECT,
                             .default = LE_RECT)) |> 
  select(-c(.LE_GEAR, .LE_MSZ, .LE_MET6, .LE_RECT))
# Once we have few more things sorted out, like state and split-among-ping
#  we would in end sum the stuff, like:
dx <- dy <- 0.05 # csquare
final <- 
  duck_trails |> 
  mutate(year = year(SI_DATIM),
         month = month(SI_DATIM),
         lon = SI_LONG%/%dx * dx + dx/2,
         lat = SI_LATI%/%dy * dy + dy/2) |> 
  group_by(year, month, lon, lat, LE_GEAR, LE_MET6) |> 
  summarise(pings = n(),
            .groups = "drop") # |> 
# collect() # get an error if not interactive

```

